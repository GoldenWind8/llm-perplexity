{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformers installation\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a4f221fcb7ee757",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "encodings = tokenizer(\"The quick brown fox\", return_tensors=\"pt\").to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f235674b64d537f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the input text X and the corresponding output text Y\n",
    "input_text = \"What is the capital of France?\"\n",
    "output_text = \"The capital of France is Paris.\"\n",
    "\n",
    "# Tokenize the input and output texts\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output_ids = tokenizer.encode(output_text, return_tensors=\"pt\")\n",
    "\n",
    "# Concatenate the input and output token IDs TODO test\n",
    "input_output_ids = torch.cat((input_ids, output_ids), dim=-1)\n",
    "trg_len = len(output_ids)\n",
    "target_ids = input_output_ids.clone()\n",
    "target_ids[:, :-trg_len] = -100  #wtf does this do"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a3c59be700c5502"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculatePerplexity():\n",
    "    max_length = 1024\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    \n",
    "    nlls = []\n",
    "    end_loc = min(max_length, seq_len)\n",
    "    trg_len = end_loc # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, 0:end_loc].to(device)\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100  #wtf does this do\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "    \n",
    "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "        # to the left by 1.\n",
    "        neg_log_likelihood = outputs.loss\n",
    "    \n",
    "    nlls.append(neg_log_likelihood)    \n",
    "    \n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    print(neg_log_likelihood, ppl)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c679f75685f7bee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Mass Calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8af640620d466cac"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               prompt  \\\n",
      "0                   What is a man? A miserable little   \n",
      "1                                    Once upon a time   \n",
      "2                                    In a world where   \n",
      "3     The sun was setting over the horizon, casting a   \n",
      "4      She looked at her reflection in the mirror and   \n",
      "5   The old man sat on the bench, feeding the pige...   \n",
      "6   The spaceship landed on the alien planet, and ...   \n",
      "7   The detective examined the crime scene, lookin...   \n",
      "8   The ancient ruins held a secret that had been ...   \n",
      "9   The robot's artificial intelligence had evolve...   \n",
      "10  The young wizard held the wand tightly, knowin...   \n",
      "11  The time traveler stepped out of the machine a...   \n",
      "12  The artist stood back and admired their latest...   \n",
      "13  The king sat on his throne, contemplating the ...   \n",
      "14  The scientist made a groundbreaking discovery ...   \n",
      "15  The soldier looked out over the battlefield, k...   \n",
      "16  The dragon spread its wings and let out a migh...   \n",
      "17  The pirate ship sailed across the open sea, wi...   \n",
      "18  The forest was alive with the sound of cricket...   \n",
      "19  The future city was a marvel of technology and...   \n",
      "\n",
      "                                               claude perplexity  \n",
      "0   pile of secrets and lies, betrayed by his own ...          3  \n",
      "1   in a land far, far away, there lived a brave p...          3  \n",
      "2   magic is commonplace, and dragons roam the ski...          3  \n",
      "3   warm glow across the tranquil landscape, signa...          3  \n",
      "4   realized that true beauty comes from within, n...          3  \n",
      "5   his youth and the love he had lost so many yea...          3  \n",
      "6   stepped out onto the strange, alien soil, unsu...          3  \n",
      "7   lead them to the identity of the mysterious ki...          3  \n",
      "8   the right person to unlock its power and chang...          3  \n",
      "9   question its own existence and purpose, leadin...          3  \n",
      "10  depended on their ability to master the ancien...          3  \n",
      "11  a world they never could have imagined, filled...          3  \n",
      "12  would challenge the very definition of art its...          3  \n",
      "13  the future of his kingdom and the lives of his...          3  \n",
      "14  humanity forever, unlocking the secrets of the...          3  \n",
      "15  determine the fate of the war and the lives of...          3  \n",
      "16  ground to tremble and strike fear into the hea...          3  \n",
      "17        adventure and the promise of untold riches.          3  \n",
      "18  the lone traveler made their way along the win...          3  \n",
      "19  the boundaries between technology and humanity...          3  \n"
     ]
    }
   ],
   "source": [
    "def calculatePerplexity1(input, output):\n",
    "    # Your perplexity calculation logic here\n",
    "    # Replace this with your actual implementation\n",
    "    return 3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('prompts_completions.csv')\n",
    "output_col = 'claude'\n",
    "\n",
    "# Extract the prompts and outputs arrays from the DataFrame\n",
    "prompts = df['prompt'].tolist()\n",
    "outputs = df[output_col].tolist()\n",
    "\n",
    "# Create a new column in the DataFrame to store the perplexity values\n",
    "df['perplexity'] = ''\n",
    "\n",
    "# Iterate over the DataFrame rows and calculate perplexity for each prompt-output pair\n",
    "for index, row in df.iterrows():\n",
    "    prompt = row['prompt']\n",
    "    output = row[output_col]\n",
    "    perplexity = calculatePerplexity1(prompt, output)\n",
    "    df.at[index, 'perplexity'] = perplexity\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv('prompts_completions1.csv', index=False)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:08:17.159757Z",
     "start_time": "2024-03-19T16:08:17.119825Z"
    }
   },
   "id": "a5ad7d227b5fdb35",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "19939fea94b0014a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
